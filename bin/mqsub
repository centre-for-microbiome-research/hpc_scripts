#!/usr/bin/env python3.4

# Must be python3.4-compatible since that is what is on the lyra base

# Script to more easily submit jobs to the QUT HPC queuing system

__author__ = "Ben Woodcroft"
__copyright__ = "Copyright 2020"
__credits__ = ["Ben Woodcroft"]
__license__ = "GPL3"
__maintainer__ = "Ben Woodcroft"
__email__ = "benjwoodcroft near gmail.com"
__status__ = "Development"

import argparse
import logging
import sys
import os
import tempfile
import subprocess
import getpass
import shutil
import re
from datetime import date
import json
import time
from smtplib import SMTP

## Code below copied from the extern python package. Copy the code here so there are no dependencies.

def run(command, stdin=None):
    '''
    Run a subprocess.check_output() with the given command with
    'bash -c command'
    returning the stdout. If the command fails (i.e. has a non-zero exitstatus),
    raise a ExternCalledProcessError that includes the $stderr as part of
    the error message

    Parameters
    ----------
    command: str
        command to run
    stdin: str or None
        stdin to be provided to the process, to subprocess.communicate.

    Returns
    -------
    Standard output of the run command

    Exceptions
    ----------
    extern.ExternCalledProcessError including stdout and stderr of the run
    command should it return with non-zero exit status.
    '''
    #logging.debug("Running extern cmd: %s" % command)

    using_stdin = stdin is not None
    process = process = subprocess.Popen(
        ["bash",'-o','pipefail',"-c", command],
        stdin= (subprocess.PIPE if using_stdin else None),
        stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    stdout, stderr = process.communicate(stdin)

    if process.returncode != 0:
        raise ExternCalledProcessError(process, command, stdout.decode(), stderr.decode())
    return stdout

class ExternCalledProcessError(subprocess.CalledProcessError):
    def __init__(self, completed_process, command, stdout, stderr):
        self.command = command
        self.returncode = completed_process.returncode
        self.stderr = stderr
        self.stdout = stdout
        self.completed_process = completed_process

    def __str__(self):
        return "Command %s returned non-zero exit status %i.\n"\
            "STDERR was: %sSTDOUT was: %s" % (
                self.command,
                self.returncode,
                self.stderr,
                self.stdout)


class PbsJobInfo:
    @staticmethod
    def json(job_id):
        return json.loads(run("qstat -x -f {} -F json".format(job_id)).decode())['Jobs'][job_id]

    @staticmethod
    def status(job_id):
        json_result = PbsJobInfo.json(job_id)
        return json_result['job_state']

    @staticmethod
    def stdout_and_stderr_paths(job_id):
        json_result = PbsJobInfo.json(job_id)
        reg = re.compile("^.*?:(.*)$")
        out1 = json_result['Output_Path']
        err1 = json_result['Error_Path']
        return reg.match(out1).group(1), reg.match(err1).group(1)

    @staticmethod
    def job_status_english(state):
        states = {}
        states['B'] = 'Array job has at least one subjob running'
        states['E'] = 'Job is exiting after having run'
        states['F'] = 'Job is finished'
        states['H'] = 'Job is held'
        states['M'] = 'Job was moved to another server'
        states['Q'] = 'Job is queued'
        states['R'] = 'Job is running'
        states['S'] = 'Job is suspended'
        states['T'] = 'Job is being moved to new location'
        states['U'] = 'Cycle-harvesting job is suspended due to keyboard activity'
        states['W'] = 'Job is waiting for its submitter-assigned start time to be reached'
        states['X'] = 'Subjob has completed execution or has been deleted'
        return states[state]



if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--debug', help='output debug information', action="store_true")
    #parser.add_argument('--version', help='output version information and quit',  action='version', version=repeatm.__version__)
    parser.add_argument('--quiet', help='only output errors', action="store_true")

    parser.add_argument('-t','--cpus',default=1,type=int, help="Number of CPUs to queue job with [default: 1]")
    parser.add_argument('-m','--mem','--ram',type=int, help="GB of RAM to ask for [default: 4*num_cpus]")
    parser.add_argument('--directive', help="Arbitrary PBS directory to add e.g. '-l ngpus=1' to ask for a GPU [default: Not used]")
    parser.add_argument('-q','--queue', default="-", help="Name of queue to send to, or '-' to not specify [default: '-']")
    walltime_group = parser.add_mutually_exclusive_group()
    walltime_group.add_argument('--hours',default=24*7,type=int, help="Hours to run for [default: 1 week]")
    walltime_group.add_argument('--weeks',type=int,help="Weeks to run for [default 1]")
    parser.add_argument('--name', help="Name of the job [default: first word of command]")
    parser.add_argument('--dry-run',action='store_true', help="Print script to STDOUT and do not lodge it with qsub")
    parser.add_argument('--bg',action='store_true', help="Submit the job, then quit [default: wait until job is finished before exiting]")
    parser.add_argument('--no-email',action='store_true', help="Do not send any emails, either on job finishing or aborting")
    parser.add_argument('--script', help='Script to run, or "-" for STDIN')
    parser.add_argument('--script-shell', help='Run script specified in --script with this shell [default: /bin/bash]', default='/bin/bash')
    parser.add_argument('--script-tmpdir', help="When '--script -' is specified, write the script to this location as a temporary file", default='/lustre/scratch/microbiome/tmp')
    parser.add_argument('--poll-interval', help="Poll the PBS server once every this many seconds [default: 30]", type=int, default=30)
    parser.add_argument('--no-executable-check', help="Usually mqsub checks the executable is currently available. Don't do this [default: do check]",action='store_true')
    parser.add_argument('command',nargs='*',help='command to be run')
    args = parser.parse_args()

    # Setup logging
    if args.debug:
        loglevel = logging.DEBUG
    elif args.quiet:
        loglevel = logging.ERROR
    else:
        loglevel = logging.INFO
    logging.basicConfig(level=loglevel, format='%(asctime)s %(levelname)s: %(message)s', datefmt='%m/%d/%Y %I:%M:%S %p')

    SCRIPT = 'script'
    COMMAND = 'command'

    if args.script:
        content_type = SCRIPT
        if len(args.command) != 0:
            raise Exception("Cannot specify both --script and a command")
    elif len(args.command) > 0:
        content_type = COMMAND
    else:
        raise Exception("Must specify either --script-stdin or a command")

    with tempfile.NamedTemporaryFile(prefix='mqsub_script',suffix='.sh',mode='w') as tf:
        if args.dry_run:
            tf = sys.stdout

        if args.mem is None:
            mem = 4*args.cpus
        else:
            mem = args.mem
        logging.debug("Using RAM {}".format(mem))

        cmd = args.command
        if args.name:
            jobname = args.name
        elif content_type == SCRIPT:
            if args.script == '-':
                jobname = 'stdin_mqsub'
            else:
                jobname = os.path.basename(args.script)
        else:
            jobname = cmd[0]

        whoami = getpass.getuser()
        email = '{}@qut.edu.au'.format(whoami)
        logging.debug("Using email address: {}".format(email))

        if content_type == COMMAND:
            if args.no_executable_check:
                logging.debug("Skipping executable check as requested")
            else:
                exe = cmd[0]
                environment_setting = re.compile('^[A-Z_]+=')
                exe_index = 0

                # Deal with e.g. PATH=extra:$PATH ...
                while environment_setting.match(exe) != None:
                    logging.info("Skipping command fragment {} as detected as being an environment setting".format(exe_index))
                    if exe_index >= len(cmd):
                        raise Exception("Failed to parse an executable from the command given")
                    exe_index += 1
                    exe = cmd[exe_index]
                    jobname = exe

                logging.debug("Testing if executable {} is available in $PATH".format(exe))
                if shutil.which(exe) is None:
                    raise Exception("The executable {} is not available, not continuing".format(exe))
                logging.debug("Executable {} was available, seems all good", exe)
        else:
            logging.debug("Not checking for executable availability as args.command not defined")

        jobname = jobname.replace("/","_")
        logging.debug("Naming job as: {}".format(jobname))

        hours = 'programming_error'
        if args.weeks is not None:
            hours = 168*args.weeks
        else:
            hours = args.hours

        print('#!/bin/bash -l',file=tf)
        print('#PBS -N {}'.format(jobname),file=tf)
        print('#PBS -l ncpus={}'.format(args.cpus),file=tf)
        print('#PBS -l mem={}gb'.format(mem),file=tf)
        print('#PBS -l walltime={}:00:00'.format(hours),file=tf)
        if args.bg and not args.no_email:
            print('#PBS -m ae',file=tf)
        print('#PBS -M {}'.format(email),file=tf)
        if args.directive:
            print('#PBS {}'.format(args.directive),file=tf)
        if args.queue != '-':
            print('#PBS -q {}'.format(args.queue),file=tf)

        # cd to current directory
        print("cd '{}'".format(os.getcwd()), file=tf)

        # activate the conda environment from which this script was started
        current_conda_env = os.environ['CONDA_PREFIX']
        if current_conda_env:
            print('. /pkg/suse12/software/miniconda3/4.5.12/etc/profile.d/conda.sh',file=tf)
            print('conda activate',file=tf)
            print("source activate '{}'".format(current_conda_env),file=tf)

        if content_type == COMMAND:
            print(' '.join(cmd),file=tf)
        elif content_type == SCRIPT:
            if args.script == '-':
                with tempfile.NamedTemporaryFile(
                    prefix='mqsub_stdin_{}_{}'.format(getpass.getuser(), date.today().strftime("%d%m%Y")),
                    suffix='.sh',
                    dir=args.script_tmpdir,
                    delete=False,
                    mode='w') as stdin_tf:

                    script_path = stdin_tf.name
                    line_count = 0
                    for l in sys.stdin:
                        stdin_tf.write(l)
                        line_count += 1
                    logging.info("Wrote {} lines of stdin to the tempfile {}".format(line_count, script_path))
                # Delete the script after completion so it cleans up, but keep the exitstatus of the original script as the exitstatus of the qsub
                print('{} {} && rm {}'.format(args.script_shell, script_path, script_path),file=tf)
            else:
                script_path = args.script
                print('{} {}'.format(args.script_shell, script_path),file=tf)

        tf.flush()

        def report_running_host(jobinfo):
            if jobinfo['job_state'] == 'R':
                logging.info("Job is running on exec_host {}".format(jobinfo['exec_host']))

        if args.dry_run:
            logging.info("Not running qsub since this is a dry run")
            sys.exit(0)
        else:
            qsub_stdout = run("qsub {}".format(tf.name)).decode()
            logging.info("qsub stdout was: {}".format(qsub_stdout.rstrip()))
            if not args.bg:
                match_result = re.compile('^(\d+\.pbs)\n$').match(qsub_stdout)
                if match_result is None:
                    raise Exception("Unexpected output from qsub: {}".format(qsub_stdout))
                else:
                    job_id = match_result.group(1)

                last_jobinfo = PbsJobInfo.json(job_id)
                last_status = last_jobinfo['job_state']
                logging.info('First status of job is {}: {}'.format(last_status, PbsJobInfo.job_status_english(last_status)))
                report_running_host(last_jobinfo)
                while True:
                    if last_status == 'F':
                        break

                    current_job_info = PbsJobInfo.json(job_id)
                    current_job_status = current_job_info['job_state']
                    if current_job_status != last_status:
                        logging.debug("last was '{}', current was '{}'".format(last_status, current_job_status))
                        logging.info('Now status of job is {}: {}'.format(current_job_status, PbsJobInfo.job_status_english(current_job_status)))
                        report_running_host(current_job_info)
                        last_status = current_job_status

                    if last_status == 'F':
                        break

                    logging.debug('Not finished (is {}), sleeping for {} seconds'.format(last_status, args.poll_interval))
                    time.sleep(args.poll_interval)

                logging.info("Job has finished")

                j = PbsJobInfo.json(job_id)
                exit_status = j['Exit_status']
                if exit_status != 0:
                    logging.error("Script appears to have failed. Exited with exit code {}".format(exit_status))
                r = j['resources_used']
                logging.info("resources_used.walltime: {}".format(r['walltime']))
                logging.info("resources_used.cpupercent: {}".format(r['cpupercent']))
                logging.info("resources_used.cput: {}".format(r['cput']))
                logging.info("resources_used.vmem: {}".format(r['vmem']))

                stdout_path, stderr_path = PbsJobInfo.stdout_and_stderr_paths(job_id)
                with open(stdout_path,'r') as f: # Possible this might fail if the stdout is binary?
                    shutil.copyfileobj(f, sys.stdout)
                with open(stderr_path,'r') as f:
                    shutil.copyfileobj(f, sys.stderr)

                if not args.no_email:
                    msg = "job: {}\n".format(job_id)\
                        +"exit status: {}\n".format(exit_status)\
                        +"resources_used.walltime: {}\n".format(r['walltime'])\
                        +"resources_used.cpupercent: {}\n".format(r['cpupercent'])\
                        +"resources_used.cput: {}\n".format(r['cput'])\
                        +"resources_used.vmem: {}\n".format(r['vmem'])
                    if content_type == SCRIPT:
                        msg = msg+"\nscript_path: {}\n".format(args.script)
                    else:
                        msg = msg+"\ncommand: {}\n".format(' '.join(args.command))
                    msg = msg+"\n this message was sent by mqsub.\n"

                    if exit_status == 0:
                        subject = 'mqsub process {} finished running with exit status 0'.format(jobname)
                    else:
                        subject = 'FAIL: mqsub process {} finished running with exit status {}'.format(jobname, exit_status)
                    with SMTP(host='localhost',port=0) as smtp:
                        smtp.sendmail('CMR_HPC',email,'Subject: {}\n\n{}'.format(subject,msg))

                os.remove(stdout_path)
                os.remove(stderr_path)
                sys.exit(exit_status)

            else:
                print("qsub stdout: {}".format(qsub_stdout), file=sys.stderr)

